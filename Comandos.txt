1) Arrancamos el docker

# sudo docker run --hostname=quickstart.cloudera --privileged=true -t -i --cpus=8 -v /home/josefigueirasm/Repositorios/practicaMapReduce:/home/cloudera/practicas --publish-all=true -p 7180 cloudera/quickstart /usr/bin/docker-quickstart

Nota: en mi caso tengo que lanzarlo como root

El contenido de la carpeta /home/ana/practicas_ICS_Mapreduce  que es del host se comparte/monta en la carpeta /home/cloudera/practicas  del guest

La instrucción --cpus=4 es porque en este portatil hay 2 procesadores y los otros 2 se emulan vía hiperthreading.. Esta instrucción puede obviarse


Cada vez que arrancamos un contenedor nuevo, empezamos desde cero, no se conservan las cosas. Para ello hay que relanzar un contenedor con 
el que hayamos trabajado

2) Modo de ver todos los contenedores

docker images



3) Para salir del contenedor es vía  

    exit  (desde la shell del docker)
    
  pero la imagen sigue viva ocupando memoria. 



4) Modo de ver los contenedores "arrancados" (cuyas imágenes están creadas)

docker ps -a


5) Para matar las imagenes "vivas"

  borramos todas las "vivas"

      docker rm `docker ps -aq -f status=exited`
      
  borramos una imagen "viva" que tiene un id_image
       
      docker rm id_image
      
6)  Modo de relanzar la imagen de un docker (podemos seguir trabajando con lo que hayamos hecho):
  
    Relanza la última (hay que hacer los dos pasos)
    
    docker start  `docker ps -q -l` # restart it in the background
    docker attach `docker ps -q -l` # reattach the terminal & stdin
    
    
    Relanzar el contenedor que tenga un ID asociado
    
    docker start ID
    docker attach  ID
    
    
    
    
    
 7) Carpeta del host /home/ana/practicas_ICS_Mapreduce 
 
    Carpeta del guest (contenedor) compartida: /home/cloudera/practicas
    
    
 8)  Pasar una carpeta/fichero a formato hdfs:
 
     $hdfs dfs -put  directorio_guest  directorio_hdfs (crea la carpeta directorio_guest en el sistema de carpetas distribuido.. Si no especificamos directorio_hdfs, la carpeta directorio_guest va a estar colgada del /   del sistema de ficheros distribuidos. Si especificamos directorio_hdfs crea dicha carpeta en el sistema de ficheros distribuidos)
     ($/usr/bin/hdfs     en caso que que no se haya especificado que hace $hdfs)

     
     
     # hdfs dfs -put /home/cloudera/practicas/contar_palabras2/libros
     
     paso la carpeta     
 
 9) Hacer un "ls" de los ficheros que tenemos en el sistema de ficheros distribuido
 
     $hdfs dfs -ls  directorio_hdfs   (directorio_hdfs es un directorio que tenemos en el sistema de ficheros distribuido)
     ($/usr/bin/hdfs dfs -ls)
     
     
     # hdfs dfs -ls    (lista todo lo que tenemos en el raíz (/) del sistema de ficheros distribuido)
     
     # hdfs dfs -ls libros  (lista el contenido de lo que hay en la carpeta libros del sistema de ficheros distribuido)
     
     
 10) Lanzar código
 
   #/usr/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar  -input libros -output salida_libros -mapper mapper.py -reducer reducer.py -file mapper.py -file reducer.py
   
    
    Nota: No puede haber carpetas dentro de carpetas, la carpeta libros sólo puede contener ficheros
    
    
    
 11) El resultado se guarda en la carpeta   "salida_libros".
     Dentro de dicha carpeta hay dos ficheros (si todo ha sido exitoso)
     
     El resultado de la ejecución se guarda en : part-00000

     
 12) El resultado lo podemos ver pasándolo a nuestro directorio de carpetas usual:
 
    # hdfs dfs -get salida_libros /home/cloudera/practicas/.
    
    Ahora en /home/cloudera/practicas/ tenmeos la carpeta salida_libros2
     
 10) Podemos indicar el número de reducers:
 
 	# PARA LANZAR EJERCICIO 1: /usr/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar  -D mapred.job.maps=2 -D mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator -D  mapred.text.key.comparator.options=-n -input mediciones -output salida_mediciones -mapper mapper.py -reducer reducer.py -file mapper.py -file reducer.py 
 
       # PARA LANZAR EJERCICIO 2A: /usr/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar  -D mapred.job.maps=2 -D mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator -D  mapred.text.key.comparator.options=-n -input condensed -output salida_condensed -mapper mapper.py -reducer reducer.py -file mapper.py -file reducer.py 
     
11) Ver el contenido de un fichero en formato hdfs:
     #  hdfs dfs -cat  fichero_hdfs

     #  hdfs dfs -tail fichero_hdfs
     
     #  hdfs dfs -cat fichero_hdfs |sort -k 2 -n (ver el fichero ordenado)
     
12 Borrar carpeta en hdfs:
    
     # hdfs dfs -rm -r directorio_hdfs
     
Para ejercicio 2

       #/usr/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar  -D mapred.job.maps=2 -input Apr95 -output salida_apr95
	       -mapper mapper.py -file mapper.py
	       
      #/usr/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar  -D mapred.job.maps=2 -input Apr95 -output salida_apr95
       -mapper mapper.py -reducer reducer.py -file mapper.py -file reducer.py
     
     
